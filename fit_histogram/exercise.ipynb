{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogramming and fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exercise is to try something that is very commonly done: taking some data, making a histogram, and then fitting it. You can work from this notebook, since notebooks aren't just for a bunch of code but can also contain text, headers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some things that we are going to need for sure: numpy, matplotlib, scipy. Best put them all at the start of your notebook. Write the imports in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat little trick: you can stow away your imports in a separate notebook, and run it from this one. This is done with something called 'cell magic' (no joke). Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'def.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a text file in this folder called 'data.txt'. Read it in with your favorite package. If this costs you more than one line, you're being inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use matplotlib to plot a histogram. Try the following arguments (for example) range=(-1, 2), bins=100, histtype='step', normed=True. See what the arguments do and find your best-looking plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(...)\n",
    "...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guessing the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needless to say, the distribution looks Gaussian. A good starting point for a fit is often just to plot the fit function on top of the histogram. Define a fit function and try a few values until you find some good starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, A, mu, sigma):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(...) # Here comes the histogram\n",
    "plt.plot(...) # Here comes the fit plot\n",
    "...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, you don't directly fit the histogram, but you rather take the data from it first and then fit that. Extract the data from the histogram with the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts, bin_edges, _ = plt.hist(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to *show* the histogram, use np.histogram instead. It has the same syntax, but doesn't take all the plot style arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts, bin_edges = np.histogram(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the bin *edges* are extracted. For a fit, we want to have the bin *centers*. Note that this list is one element shorter. Extract the bin centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_centers = ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check, plot the counts versus the bin_centers and see that it resembles the histogram. If you want, you can do 'ls=steps' or 'ls=steps_mid' for a more histogrammy look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the extracted histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fit your Gaussian function with curve_fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(... , ..., ..., p0=[..., ..., ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For documentation on curve_fit, execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curve_fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing this cell, you get some values out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the optimized values. But wait! Did we put the errors in somewhere? No, so curve_fit just guesses them. In fact, we do know the bin-by-bin errors, since we're doing a counting experiment (yay particle physics!). The error on the number of counts is just the square root, in the limit of large N. Let's extract the error on the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_err = np.sqrt(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have zero counts somewhere, the counts will go zero too and your fitting will fail. Check if there are zeros in your error array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may or may not be zeros in there. Write a function to replace all zeros in an array with ones. Can you do a one-liner again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_zeros(arr):\n",
    "    ...\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_err = replace_zeros(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, refit and check the influence on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popt0, pcov0 = curve_fit(... , ..., ..., p0=[..., ..., ...], )\n",
    "popt1, pcov1 = curve_fit(... , ..., ..., p0=[..., ..., ...], sigma=counts_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('No   errs: ', popt0)\n",
    "print('With errs: ', popt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy also returns the covariance matrix, pcov. If the errors are not correlated (check this for any serious analysis, but assume here), this is how you get the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perr = np.sqrt(np.diag(pcov1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, time to print your result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('==== My awesome fit! =======')\n",
    "print('A:     %.4f +- %.4f' % (popt1[0], perr[0]))\n",
    "print('mu:    %.4f +- %.4f' % (popt1[1], perr[1]))\n",
    "print('sigma: %.4f +- %.4f' % (popt1[2], perr[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bins, fit range, and your result..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, wasn't that easy? But wait, *you* put in the number of bins and the histogram range. Doesn't that influence your result? Well, maybe. Let's try two methods. First, let's vary the fit range and number of bins and see what it does to the results. After that, we can try something a little more advanced: unbinned fits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that does all you've just done: extract the histogram, bin it, get the data, fit it, return the parameters. Be sure to put comments in, because this will be a longer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_it(arr, hist_range, hist_bins):\n",
    "    # Make a histogram and extract the data\n",
    "    ...\n",
    "    \n",
    "    # Get the bin centers\n",
    "    ...\n",
    "    \n",
    "    # Get the errors\n",
    "    ...\n",
    "    \n",
    "    # Replace with ones if zeros are found\n",
    "    ...\n",
    "    \n",
    "    # Fit it\n",
    "    ...\n",
    "    \n",
    "    # Optional: plot the fitted gaussian\n",
    "    ...\n",
    "    \n",
    "    return popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, vary the number of bins and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_bins = ... # List or array of the number of bins you'd like to try\n",
    "popts = np.array([fit_it(...) for hist_bins in try_bins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens to the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(try_bins, popts[:, 0])\n",
    "plt.ylabel('A')\n",
    "plt.xlabel('Nbins')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(try_bins, popts[:, 1])\n",
    "plt.ylabel('mu')\n",
    "plt.xlabel('Nbins')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(try_bins, popts[:, 2])\n",
    "plt.ylabel('sigma')\n",
    "plt.xlabel('Nbins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing for the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what you have just seen, do you think the uncertainties you got before are OK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(perr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbinned fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbinned fits are a little more tricky: you don't get the nice curve_fit routine, but on the plus side: no dependence on fit range, no stupid unphysical zero errors and you can impress everyone by saying 'unbinned fit'. Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting is the process of minimizing the negative log likelihood. Wow. For this, we define the probability density function: in our case, just the Gaussian again, but normalized. Define it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss_norm(x, mu, sigma):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the log likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loglikelihood(arr, mu, sigma):\n",
    "    return np.log(gauss_norm(arr, mu, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what we wish to minimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neglog(mu, sigma):\n",
    "    return - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the behavior: if we fix sigma to (approximately) the right value and vary mu, what does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_fix = ...\n",
    "mu_guesses = ... #\n",
    "values = [... for mu in mu_guesses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(mu_guesses, values)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a minimizing routing (scipy.optimize.minimize, for example, or iMinuit if you have it installed) to find the best-fit values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't got enough already, try:\n",
    "  * Limiting the data to see what happens at lower statistics.\n",
    "  * Read the data with uniform background, and modify the fit function to take it into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
